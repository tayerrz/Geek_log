<p>你好，我是陈现麟。</p><p>在上周的期中测试环节，我留了一道 IM 系统的架构设计题，相信你一定进行了深入的思考，可能还产生了一些疑问。那么在本节课中，我就来详细地解答一下，如何依据业务和架构的需求来设计一个 IM 系统。</p><h2>问题回顾</h2><p>首先，我们来回顾一下 IM 系统的业务和架构方面的需求。</p><p><strong>业务上的需求</strong>：</p><ul>
<li>支持单聊。</li>
<li>100 个人以内的群聊。</li>
<li>峰值同时在线 1000 w。</li>
<li>峰值发送消息 10 w QPS。</li>
</ul><p><strong>架构上的需求</strong>：</p><ul>
<li>开发模式简单，新功能支持快速迭代。</li>
<li>长连接支持就近接入和负载均衡。</li>
<li>分层设计。</li>
<li>在功能迭代上线的时候，不要影响到用户已经建立好的长连接。</li>
<li>发送消息的接口是幂等的。</li>
</ul><h2>问题解析</h2><p>基于这些业务和架构上的需求，我完成了一个架构设计，具体见下图。接下来，我们就基于这个设计图来回答期中测试的问题。这里要特别说明一点，如果你的架构设计和我的不一样，也不一定就是错了。我们在做架构设计的时候，都是在不断地做 trade-off，很多方案没有绝对的对与错，只有深入理解业务，才能做出更适合业务场景的架构设计。</p><p><img src="https://static001.geekbang.org/resource/image/08/25/08ffb179c06ca303d05447ff48449e25.jpg?wh=2284x1432" alt=""></p><p>1.IM 系统一般都会涉及基于 TCP 的长连接通道和基于 HTTP(S) 的短连接通道，你认为长连接通道和短连接通道的职责分别是什么？</p><p>长连接在客户端和服务器端都需要维护状态，并且消息是异步收发的，我们对长连接的设计应该尽量简单，而短连接可以理解为无状态的，并且请求是同步处理的，方便去完成一些复杂的功能，所以我认为一个比较好的职责划分方式是：</p><!-- [[[read_end]]] --><ul>
<li><strong>长连接作为信令通道，用于服务端主动给客户端发送信令通知</strong>，例如有新消息之类的主动通知，信令通知的数据结构做通用设计，在扩展的时候，新增信令类型的枚举即可。</li>
<li><strong>短连接作为业务通道，用于实现业务功能，客户端通过短连接请求服务器的 API</strong> <strong>，来完成业务功能</strong>，例如长连接通道发送有新消息的信令后，客户端通过短连接请求获得消息之类的接口，得到新消息的内容和顺序。</li>
</ul><p>2.长连接的就近接入和负载均衡应该怎么来做？（可以考虑通过设计一个路由服务来解决。）</p><p>设计一个路由服务，客户端在建立长连接之前，先请求路由服务，路由服务通过客户端的 IP 或者 GPS 等位置信息，在充分考虑就近接入和负载均衡的基础上，给客户端返回最合适的接入点。</p><p>3.整个 IM 系统应该怎么分层？每一层的职责是什么？（可以考虑从长连接接入、Push 和 IM 等方面来进行分层。）</p><p><strong>这个 IM 系统可以分为 3 层：接入层、Push 层 和 IM 层</strong>，它们具体的职责为：</p><ul>
<li>
<p>接入层：</p>
<ul>
<li>外部路由服务：负责长连接服务的发现、负载均衡和连通性保障。</li>
<li>长连接服务：负责长连接高效高质量的鉴权、接入和数据发送，它与业务无关，长连接 ID 为全局唯一 ID 即可，不要包含任何业务信息。</li>
<li>网关服务：负责接入短连接请求，以及鉴权相关网关职责功能。</li>
</ul>
</li>
<li>
<p>Push 层：</p>
<ul>
<li>Push 服务：负责服务器对客户端的信令推送，由于信令一般都是通过用户 ID 来发送的，所以在 Push 层需要做一个绑定操作，将用户 ID 和长连接 ID 进行绑定，在发送推送的时候，通过用户 ID 找到长连接 ID，然后再发送推送的信令数据。</li>
<li>内部路由服务：存储长连接与长连接服务的对应关系，提供通过长连接 ID 查询长连接服务实例的接口。</li>
</ul>
</li>
<li>
<p>IM 层：负责 IM 层的业务逻辑，主要的业务功能都通过短连接的 API 对外提供，如果服务器需要主动通知客户端，则通过 Push 层来发送信令。</p>
</li>
</ul><p>4.在系统设计中，如何让功能在迭代上线的时候，不要影响到用户已经建立好的长连接呢？</p><p>在上面的分层中，<strong>我们接入层长连接服务的设计与业务无关，并且信令的数据结构易扩展</strong>，这样可以保证业务功能迭代上线时，只需要发布 IM 层的服务，而长连接服务几乎不需要迭代升级，这也就保证了在功能上线时，不会影响到用户已经建立好的长连接。</p><p>5.对于业务需求，IM 系统的消息扩散模式，采用读扩散还是写扩散？为什么？</p><p><strong>因为业务需求为单聊和 100 人以内的群聊，所以我们可以采用写扩散的模式</strong>，为每一个用户建立一个“收件箱”，该用户在每一次收到消息后，我们都向用户的收件箱写入一条数据，这样用户在获取新消息的时候，只需要拉取收件箱的数据即可。</p><p>而对于微博这样的关注模式，一个明星用户可能有 1000 w 的粉丝，如果采用写扩散，那么一个明星用户发布一条微博，就会导致 1000 w 次写“收件箱”，所以这种情况下，<strong>我们一般采用读扩散，用户拉取微博消息列表的时候，即用户读微博信息的时候，根据关注用户发布的微博列表来生成微博消息列表</strong>。</p><p>其实，<strong>很多的场景为了满足业务要求，会通过写扩散和读扩散的混合模式来进行消息的扩散</strong>，如果一条消息的接收者非常多，则采用读扩散，否则采用写扩散。</p><p>6.如何保障消息的发送接口是幂等的？</p><p>客户端在发送消息时，生成唯一 ID，唯一 ID 的生成逻辑可以按以下的方式生成：</p><center>
<p><strong>唯一 ID = Hash（UID + DID + 时间戳 + 自增计数）</strong></p>
</center><p>其中，UID 为用户 ID，DID 为设备 ID，自增计数为同一个时间戳下发送的消息数。然后我们可以依据<a href="https://time.geekbang.org/column/article/485201">第 8 讲重试幂等</a>中的“至少一次消息传递加消息幂等性”的方式来处理。</p><p>7.如果要对 IM 系统进行限流，你认为应该在哪几个地方来实施？为什么？</p><p>我认为可以在下面三个地方进行限流：</p><ul>
<li>接入层，保证接入点不会出现过载的情况，所以我们可以<strong>对路由服务进行限流</strong>。超过阈值，则返回客户端当前不能建立新的连接，让客户端等待一段时间后再重试，这个时间依据当时的情况而定。</li>
<li>Push 层，整个 Push 层的关键是信令通道的正常，所以<strong>对推送信令的 QPS 进行限流</strong>，并且由于很多对 IM 层接口的访问，都是收到信令后的动作，比如收到有新消息的信令，就会执行获得消息相关的接口，那么减少信令数也可以减少对 IM 层接口的访问。</li>
<li>网关服务或者 IM 服务，整个 IM 层的关键是消息发送和获取消息相关的接口，所以我们可以<strong>对消息发送和获取消息相关的接口进行限流</strong>，确保这些接口和服务的正常性。</li>
</ul><p>8.如何提高长连接和短连接通道的连接成功率？</p><p>关于这个问题，你可以具体查看<a href="https://time.geekbang.org/column/article/490456">第 15 讲“被动故障的预案梳理”</a>，其中关于 DNS 解析问题和网络连通性问题的预案，就能解答你的疑惑。</p><p>9.整个 IM 系统要满足业务需求的指标，大约需要多少机器资源？是怎么计算的？</p><p>这部分我们一起按照业务的需求，来估算所需要的机器数量，注意，这里只是估算，不是绝对准确的数据。</p><ul>
<li>接入层：如果我们决定通过一个接入实例承载 100 w 长连接，通过 10 个接入实例承担 1000 w 的长连接，那么一个实例运行的配置为：
<ul>
<li>内存：一个 TCP 连接在接入服务运行的系统上，最大消耗的内存为 8 k 左右，那么为了支撑 100 w 长连接需要 8 G 内存，还需要为业务层内存保留 8 G 内存，另外，期望支持 100 w 长连接的时候，系统的内存使用率为 50%，所以，最终内存为<strong> 32 G</strong>。</li>
<li>CPU：因为接入层为 IO 密集型服务，所以CPU 和内存的配比为 1：1，<strong>CPU 为 32 核</strong>。</li>
</ul>
</li>
<li>Push 层：峰值发送消息 10 w QPS，考虑到群消息会放大消息数量，我们预估放大 1 倍为 20 w QPS。假设经过我们的测试， 32 核 32 G 的机器可以支撑 5 w QPS 的信令推送，并且预留一定的空间，那么最终需要<strong> 5 台 32 核 32 G 的机器</strong>。</li>
<li>IM 层：峰值发送消息为 10 w QPS，对应消息发送 API 的 QPS 为 10 w，如上讨论，信令推送的 QPS 为 20 w QPS，对应消息拉取 API 的 QPS 为 20 w QPS，IM 层其它的 API 接口预估 10 w QPS，可以得出 IM 层 API 接口总计 40 w QPS。假设经过我们的测试， 32 核 32 G 的机器，可以支撑 5 w QPS 的 IM 层 API 接口的调用，并且预留一定的空间，最终需要<strong> 10 台 32 核 32 G 的机器</strong>。</li>
</ul><p>通过这一次期中测试，我们对“分布式计算篇”的知识，以及架构设计的一些思想进行了查漏补缺，如果你完成得很好，请不要骄傲，接下来的学习中还要继续温故而知新；如果你在完成时，遇到了很多问题或者成绩并不好，也不要灰心丧气，现在你知道了不擅长的部分或者不懂的知识，一定要抓紧时间认真复习，有不明白的地方欢迎和我在留言区交流，继续加油！</p>